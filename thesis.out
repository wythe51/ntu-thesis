\BOOKMARK [0][-]{chapter*.1}{摘要}{}% 1
\BOOKMARK [0][-]{chapter*.2}{Abstract}{}% 2
\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 3
\BOOKMARK [0][-]{chapter.2}{Related\040Work}{}% 4
\BOOKMARK [1][-]{section.2.1}{Difficulties\040in\040training\040deep\040nerual\040networks}{chapter.2}% 5
\BOOKMARK [1][-]{section.2.2}{Representation\040power\040of\040deep\040neural\040network}{chapter.2}% 6
\BOOKMARK [0][-]{chapter.3}{Vanishing\040Nodes:\040correlation\040between\040hidden\040nodes}{}% 7
\BOOKMARK [1][-]{section.3.1}{Vanishing\040Node\040Indicator}{chapter.3}% 8
\BOOKMARK [1][-]{section.3.2}{Impacts\040of\040back-propagation}{chapter.3}% 9
\BOOKMARK [1][-]{section.3.3}{Representation\040power\040vanishes\040as\040the\040network\040goes\040deeper}{chapter.3}% 10
\BOOKMARK [1][-]{section.3.4}{The\040effect\040of\040the\040orthogonal\040weight\040matrices\040to\040the\040representation\040power}{chapter.3}% 11
\BOOKMARK [1][-]{section.3.5}{Representation\040power\040of\040residual-like\040architectures}{chapter.3}% 12
\BOOKMARK [0][-]{chapter.4}{Variance\040propagation\040of\040deep\040neural\040networks}{}% 13
\BOOKMARK [1][-]{section.4.1}{Comparison\040with\040exploding/vanishing\040gradients}{chapter.4}% 14
\BOOKMARK [1][-]{section.4.2}{Norm-preserving\040weight\040initialization}{chapter.4}% 15
\BOOKMARK [1][-]{section.4.3}{Batch\040normalization\040results\040in\040exploding\040gradients}{chapter.4}% 16
\BOOKMARK [1][-]{section.4.4}{T-normalization:\040A\040novel\040normalization\040method\040for\040deep\040networks}{chapter.4}% 17
\BOOKMARK [0][-]{chapter.5}{Experiments}{}% 18
\BOOKMARK [1][-]{section.5.1}{Probability\040of\040failed\040training}{chapter.5}% 19
\BOOKMARK [1][-]{section.5.2}{Analyses\040of\040failed\040training}{chapter.5}% 20
\BOOKMARK [0][-]{chapter.6}{Conclusion}{}% 21
\BOOKMARK [0][-]{chapter.6}{Bibliography}{}% 22

\begin{abstractzh}

\bigbreak
\noindent \textbf{關鍵字：}{\, \makeatletter \@keywordszh \makeatother}
\end{abstractzh}

\begin{abstracten}
    It is well known that the problem of vanishing/exploding gradients creates a challenge when 
    training deep networks. In this paper, we show another phenomenon, called \textit{vanishing nodes},
    that also increases the difficulty of training deep neural networks.
    As the depth of a neural network increases, the network's hidden nodes show more highly
    correlated behavior. This correlated behavior results in great similarity between these nodes.
    The redundancy of hidden nodes thus increases as the network becomes deeper.
    We call this problem "\textit{Vanishing Nodes}."
    This behavior of vanishing nodes can be characterized quantitatively by the network parameters,
    which is shown analytically to be proportional to the network depth and inversely proportional
    to the network width. The numerical results suggest that the degree of vanishing nodes will become
    more evident during back-propagation training. Finally, we show that vanishing/exploding gradients
    and vanishing nodes are two different challenges that increase the difficulty of training deep
    neural networks.

\bigbreak
\noindent \textbf{Keywords:}{\, \makeatletter \@keywordsen \makeatother}
\end{abstracten}

\begin{comment}
\category{I2.10}{Computing Methodologies}{Artificial Intelligence --
Vision and Scene Understanding} \category{H5.3}{Information
Systems}{Information Interfaces and Presentation (HCI) -- Web-based
Interaction.}

\terms{Design, Human factors, Performance.}

\keywords{Deep learning}
\end{comment}
